{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb36a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d20af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from utils import *\n",
    "from moe_utils import *\n",
    "from moe_architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b6b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace()\n",
    "args.lora_rank=2\n",
    "args.lora_architecture=\"moe\"\n",
    "args.num_post_train_epochs=1\n",
    "args.learning_rate=3e-4\n",
    "args.model_name=\"qwen2.5-1.5b-instruct\"\n",
    "args.learning_rate=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154f443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, config = get_model(model_name=\"qwen2.5-1.5b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59577fd4-aa46-4340-83b1-25e7841c4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_adapter_dir = f\"/scratch/doluk/Compact-Interference-PRAG/offline/{args.model_name}/rank={args.lora_rank}_alpha=32/popqa/lr=0.0003_epoch=2_direct/aug_model=qwen2.5-1.5b-instruct/total/data_0\"  # <-- set your path\n",
    "# 2) Re-inject adapters (loads frozen A/B from trained_adapter_dir)\n",
    "inject_hydra_lora(\n",
    "    model,\n",
    "    trained_data_adapters_dir=trained_adapter_dir,\n",
    "    r=args.lora_rank,\n",
    "    alpha=32,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    architecture=args.lora_architecture,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6886f3a-86b7-4984-b475-5ed56b1615c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): LinearWithCustomLoRA(\n",
       "            (base): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (custom_lora): MoELoRA(\n",
       "              (As): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=1536, out_features=2, bias=False)\n",
       "              )\n",
       "              (Bs): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=2, out_features=8960, bias=False)\n",
       "              )\n",
       "              (router): Linear(in_features=1536, out_features=3, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (up_proj): LinearWithCustomLoRA(\n",
       "            (base): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "            (custom_lora): MoELoRA(\n",
       "              (As): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=1536, out_features=2, bias=False)\n",
       "              )\n",
       "              (Bs): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=2, out_features=8960, bias=False)\n",
       "              )\n",
       "              (router): Linear(in_features=1536, out_features=3, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (down_proj): LinearWithCustomLoRA(\n",
       "            (base): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "            (custom_lora): MoELoRA(\n",
       "              (As): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=8960, out_features=2, bias=False)\n",
       "              )\n",
       "              (Bs): ModuleList(\n",
       "                (0-2): 3 x Linear(in_features=2, out_features=1536, bias=False)\n",
       "              )\n",
       "              (router): Linear(in_features=8960, out_features=3, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c5ee618-5400-47be-9a02-63475726d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "load_dir=os.path.join(TESTING_SAVE_PATH, args.lora_architecture,  f\"lr={args.learning_rate}_epoch={args.num_post_train_epochs}\")\n",
    "os.path.exists(load_dir)\n",
    "path = os.path.join(load_dir, \"adapter_model.safetensors\")\n",
    "sd = load_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed8912f-160b-4f3a-b835-7073d272da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "incompatible = model.load_state_dict(sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bced7f5-a99e-424c-aacf-50f198cb4123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.layers.0.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.0.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.0.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.0.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.0.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.0.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.1.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.1.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.1.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.1.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.1.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.1.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.10.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.10.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.10.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.10.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.10.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.10.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.11.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.11.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.11.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.11.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.11.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.11.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.12.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.12.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.12.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.12.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.12.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.12.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.13.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.13.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.13.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.13.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.13.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.13.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.14.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.14.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.14.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.14.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.14.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.14.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.15.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.15.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.15.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.15.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.15.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.15.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.16.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.16.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.16.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.16.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.16.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.16.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.17.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.17.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.17.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.17.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.17.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.17.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.18.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.18.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.18.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.18.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.18.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.18.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.19.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.19.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.19.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.19.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.19.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.19.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.2.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.2.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.2.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.2.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.2.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.2.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.20.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.20.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.20.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.20.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.20.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.20.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.21.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.21.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.21.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.21.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.21.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.21.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.22.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.22.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.22.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.22.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.22.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.22.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.23.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.23.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.23.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.23.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.23.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.23.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.24.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.24.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.24.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.24.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.24.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.24.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.25.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.25.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.25.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.25.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.25.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.25.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.26.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.26.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.26.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.26.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.26.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.26.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.27.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.27.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.27.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.27.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.27.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.27.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.3.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.3.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.3.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.3.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.3.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.3.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.4.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.4.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.4.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.4.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.4.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.4.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.5.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.5.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.5.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.5.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.5.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.5.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.6.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.6.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.6.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.6.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.6.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.6.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.7.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.7.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.7.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.7.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.7.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.7.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.8.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.8.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.8.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.8.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.8.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.8.mlp.up_proj.custom_lora.router.weight',\n",
       " 'model.layers.9.mlp.down_proj.custom_lora.router.bias',\n",
       " 'model.layers.9.mlp.down_proj.custom_lora.router.weight',\n",
       " 'model.layers.9.mlp.gate_proj.custom_lora.router.bias',\n",
       " 'model.layers.9.mlp.gate_proj.custom_lora.router.weight',\n",
       " 'model.layers.9.mlp.up_proj.custom_lora.router.bias',\n",
       " 'model.layers.9.mlp.up_proj.custom_lora.router.weight']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3864b7d-79bf-4115-948b-1dd22a2a156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in incompatible.missing_keys:\n",
    "    if \"model.layers\" in key and \"router\" in key:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, config = get_model(model_name=\"qwen2.5-1.5b-instruct\")\n",
    "\n",
    "# 2) Re-inject adapters (loads frozen A/B from trained_adapter_dir)\n",
    "inject_hydra_lora(\n",
    "    model,\n",
    "    trained_data_adapters_dir=trained_adapter_dir,\n",
    "    r=args.lora_rank,\n",
    "    alpha=32,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    architecture=args.lora_architecture,\n",
    ")\n",
    "model.to(device=DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 3) Load the trained router/mixture weights\n",
    "load_injected_adapters(model, os.path.join(TESTING_SAVE_PATH, args.lora_architecture,  f\"lr={args.learning_rate}_epoch={args.num_post_train_epochs}\"), strict=False)\n",
    "\n",
    "# 4) Run inference\n",
    "with torch.no_grad():\n",
    "    print(model_generate(\"What is George Rankin's occupation?\", model, tokenizer, config))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
