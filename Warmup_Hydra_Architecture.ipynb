{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182bf8c7-0824-4319-8875-bdb352cef195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doluk/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"src\")\n",
    "from utils import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b2bf045-3c5b-4d6d-a2e5-cbd8dd7c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from root_dir_path import ROOT_DIR\n",
    "from peft import get_peft_model\n",
    "from utils import load_data\n",
    "from encode import train\n",
    "from tqdm import tqdm\n",
    "args = SimpleNamespace()\n",
    "args.model_name = \"qwen2.5-1.5b-instruct\"\n",
    "args.lora_rank = 2\n",
    "args.lora_alpha = 32\n",
    "args.dataset = \"popqa\"\n",
    "args.data_type = \"total\"\n",
    "args.augment_model = args.model_name\n",
    "args.learning_rate = 3e-4\n",
    "args.sample=1\n",
    "args.num_train_epochs=1 \n",
    "args.with_cot=False\n",
    "args.per_device_train_batch_size=1\n",
    "data_list = load_data(args.dataset, args.data_type, args.augment_model)\n",
    "cot_name = \"cot\" if args.with_cot else \"direct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5030ee1c-d5e5-446b-9d94-7348a68ebcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, _generation_config = get_model(args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "357636c1-04c8-4947-8fe4-f6c0a50c85b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_adapter_path = os.path.join(\n",
    "            ROOT_DIR, \n",
    "            \"warmup/lora_base_weight\", \n",
    "            args.model_name, \n",
    "            \"direct\"\n",
    "        )\n",
    "\n",
    "os.path.exists(os.path.join(init_adapter_path, \"adapter_model.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa2c4916-c157-4608-a7c9-f5d0d58fcf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Solving total ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "  0%|                                                                                                                    | 0/1 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename, fulldata in data_list:\n",
    "    filename = filename.split('.')[0] \n",
    "    print(f\"### Solving {filename} ###\")\n",
    "    output_dir = os.path.join(\n",
    "        ROOT_DIR, \n",
    "        \"offline\", \n",
    "        \"warm_up\",\n",
    "        args.model_name, \n",
    "        f\"rank={args.lora_rank}_alpha={args.lora_alpha}\",\n",
    "        args.dataset,\n",
    "        f\"lr={args.learning_rate}_epoch={args.num_train_epochs}_{cot_name}\",\n",
    "        f\"aug_model={args.augment_model}\",\n",
    "        filename,\n",
    "    )\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fulldata = fulldata if args.sample == -1 else fulldata[:args.sample]\n",
    "    for did, data in tqdm(enumerate(fulldata), total=len(fulldata)):\n",
    "        augment = data[\"augment\"]\n",
    "        for pid in range(len(augment)):\n",
    "            save_path = os.path.join(output_dir, f\"data_{did}\", f\"passage_{pid}\")\n",
    "            if os.path.exists(os.path.join(save_path, \"adapter_model.safetensors\")):\n",
    "                continue\n",
    "            model = train(data[\"question\"], [augment[pid]], args, model, tokenizer, \n",
    "                        init_adapter_path, save_path)     \n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prag)",
   "language": "python",
   "name": "prag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
